{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from transformers import FlaxT5ForConditionalGeneration, AutoTokenizer, T5Config\n",
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-large\")\n",
    "trainer_config = T5Config.from_pretrained(\"t5-large\")\n",
    "\n",
    "student_config_dict = trainer_config.to_dict()  # makes it mutable\n",
    "student_config_dict[\"d_ff\"] = 1024\n",
    "student_config_dict[\"d_model\"] = 256\n",
    "student_config_dict[\"num_heads\"] = 4\n",
    "student_config_dict[\"num_layers\"] = 1\n",
    "student_config_dict[\"num_decoder_layers\"] = 1\n",
    "\n",
    "student_config = T5Config.from_dict(student_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"t5_super_tiny\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "tokenizer.save_pretrained(MODEL_DIR)\n",
    "student_config.save_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset c4 (/home/vlialin/.cache/huggingface/datasets/c4/realnewslike/0.0.0/df532b158939272d032cc63ef19cd5b83e9b4d00c922b833e4cb18b2e9869b01)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5fc1c8211840b8a26a745c4cc3bc8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': \"State Bank of India (SBI) main branch, Sector 17, in association with the Chandigarh Beopar Mandal organised a 'Coin Mela' for traders, in which coins and currency notes amounting to Rs 36 lakh were distributed. The fair will continue till Tuesday as well.\\nMohan Ganeshari, division general manager (DGM), and Kamlesh Sekhon, area general manager (AGM), SBI, inaugurated the event by distributing bags of coins and bundle of notes to traders.\\nSBI officials said that Rs 1 currency notes had already been printed by the Reserve Bank of India, and the supply would reach the RBI, Chandigarh, soon.\\nKK Rana and Venu Gopal, manager and assistant manager, currency issue department, RBI, also made people aware about Notes Return Rules, 2009, and star series notes.\",\n",
       " 'timestamp': '2019-04-22T22:06:46Z',\n",
       " 'url': 'https://www.hindustantimes.com/chandigarh/chandigarh-state-bank-of-india-holds-coin-mela-for-traders/story-QlwEu2loquMBnrSoGYSr0K.html'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4_dataset = load_dataset(\"c4\", \"realnewslike\")\n",
    "\n",
    "c4_train = c4_dataset[\"train\"]\n",
    "\n",
    "indices = np.random.choice(len(c4_train), int(len(c4_train) * 0.01), replace=False)\n",
    "c4_train = c4_train.select(indices)\n",
    "next(iter(c4_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train command\n",
    "\n",
    "```bash\n",
    "export WANDB_START_METHOD=\"thread\"\n",
    "export TOKENIZERS_PARALLELISM=false\n",
    "export MODEL_DIR=t5_super_tiny\n",
    "\n",
    "python run_t5_mlm_flax.py \\\n",
    "\t--output_dir=$MODEL_DIR \\\n",
    "\t--model_type=\"t5\" \\\n",
    "\t--config_name=$MODEL_DIR \\\n",
    "\t--tokenizer_name=$MODEL_DIR \\\n",
    "\t--dataset_name=\"c4\" \\\n",
    "\t--dataset_config_name=\"realnewslike\" \\\n",
    "\t--preprocessing_num_workers=\"8\" \\\n",
    "\t--max_seq_length=\"64\" \\\n",
    "\t--per_device_train_batch_size=\"512\" \\\n",
    "\t--per_device_eval_batch_size=\"512\" \\\n",
    "\t--adafactor \\\n",
    "\t--learning_rate=\"0.005\" \\\n",
    "\t--weight_decay=\"0.001\" \\\n",
    "\t--warmup_steps=\"2000\" \\\n",
    "\t--overwrite_output_dir \\\n",
    "\t--logging_steps=\"10\" \\\n",
    "\t--save_steps=\"1000\" \\\n",
    "\t--eval_steps=\"500\" \\\n",
    "\t# --dataset_fraction=\"0.1\" # DEBUG option, make sure that validation set is still more that 1 element\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFOM Distillation\n",
    "\n",
    "```bash\n",
    "export TOKENIZERS_PARALLELISM=false\n",
    "export MODEL_DIR=t5_2l_8h_512d_2048ff_lfom_distil_debug\n",
    "export TEACHER_MODEL=t5-small\n",
    "export WEAK_MODEL=t5_2l_8h_512d_2048ff\n",
    "\n",
    "# REMEMBER TO REPLACE --config-name $WEAK_MODEL with a normal config\n",
    "# REMEMBER TO ADD --weak_model_name_or_path\n",
    "\n",
    "python run_lfom_distillation_flax.py \\\n",
    "\t--output_dir=$MODEL_DIR \\\n",
    "\t--model_type=\"t5\" \\\n",
    "\t--config_name=$WEAK_MODEL \\\n",
    "\t--tokenizer_name=$TEACHER_MODEL \\\n",
    "\t--teacher_model_name_or_path=$TEACHER_MODEL \\\n",
    "\t--dataset_name=\"c4\" \\\n",
    "\t--dataset_config_name=\"realnewslike\" \\\n",
    "\t--preprocessing_num_workers=\"8\" \\\n",
    "\t--max_seq_length=\"256\" \\\n",
    "\t--temperature 2.0 \\\n",
    "\t--per_device_train_batch_size=\"128\" \\\n",
    "\t--per_device_eval_batch_size=\"128\" \\\n",
    "\t--adafactor \\\n",
    "\t--learning_rate=\"0.005\" \\\n",
    "\t--weight_decay=\"0.001\" \\\n",
    "\t--warmup_steps=\"2000\" \\\n",
    "\t--overwrite_output_dir \\\n",
    "\t--logging_steps=\"10\" \\\n",
    "\t--save_steps=\"1000\" \\\n",
    "\t--eval_steps=\"500\" \\\n",
    "\t--dataset_fraction=\"0.1\" # DEBUG option, make sure that validation set is still more that 1 element\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4db0e76753e035e0d8c72657e4dde1e171a015bce613565d7a010ff9669a0e1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
